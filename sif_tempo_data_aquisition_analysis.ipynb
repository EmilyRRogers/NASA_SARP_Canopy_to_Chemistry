{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc4c0af3-557c-437d-a355-07b8ee6eebf3",
   "metadata": {},
   "source": [
    "# SIF AND TEMPO DATA AQUISITION AND ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf87bb9c-d5ba-43ed-b2e1-22198753ac2b",
   "metadata": {},
   "source": [
    "Emily Rogers, NASA SARP WEST 2024\n",
    "\n",
    "Contact: erogers4@bellarmine.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f454cc8-552a-410b-bcef-cfe4308185e0",
   "metadata": {},
   "source": [
    "Acknowledgements\n",
    "\n",
    "Thank you to Dr. Barron Henderson for developing the pyrsig package for Python, and to Dr. Dan Sousa and Megan Ward-Baranyay for offering crucial guidance. I also thank Lily Lyons from the Aerosols group at NASA SARP West 2024 for guidance retrieving SIF data. This procedure includes adaptations from the resources and advice from these individuals. \n",
    "\n",
    "Source code for TEMPO- Python Interface: https://barronh.github.io/pyrsig/ \n",
    "\n",
    "Earth Data, OCO-2 SIF : https://daac.ornl.gov/cgi-bin/dsviewer.pl?ds_id=1863"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7d584f-5e37-4e2d-8a23-89a7b0058204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING AND INSTALLING LIBRARIES --------------------------------------------------\n",
    "#!python -m pip install -qq pandas xarray matplotlib netcdf4 pyproj pyrsig pycno\n",
    "import pyproj\n",
    "import xarray as xr\n",
    "import pyrsig\n",
    "import pandas as pd\n",
    "import pycno\n",
    "import getpass\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import netCDF4\n",
    "from netCDF4 import Dataset\n",
    "import calendar\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f1ee8c-22d0-4780-92d0-f4e553db22f7",
   "metadata": {},
   "source": [
    "# SELECTING BOUNDING BOXES."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc69672f-1e7b-414d-95db-de2965b9a94a",
   "metadata": {},
   "source": [
    "In my research, I selected 10 areas each from High Altitude Forests & Woodlands and Coastal Shrublands & Grasslands using Google Earth and land use maps. The following is used to iterate processes for all of these. Dr. Henderson's GitHub, linked above, has a script for processing data for a single bounding box, as does the NASA Arset training for TEMPO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab47af8-eada-4bf5-8c5f-22ac08ec6e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected locations for high altitude forest and woodlands-- TEMPO\n",
    "bbox_list= [(-118.41, 35.49, -118.40, 35.50),\n",
    "            (-118.38, 35.45, -118.37, 35.46),\n",
    "            (-118.33, 35.43, -118.32, 35.44),\n",
    "            (-117.92, 34.06, -117.91, 34.07),\n",
    "            (-116.75, 34.23, -116.74, 34.24),\n",
    "            (-116.82, 34.01, -116.81, 34.02),\n",
    "            (-117.79, 34.21, -117.78, 34.22),\n",
    "            (-116.74, 33.84, -116.73, 33.85),\n",
    "            (-117.56, 33.74, -117.55, 33.75),\n",
    "            (-117.49, 33.66, -117.48, 33.67)]\n",
    "# bbox lists set the corners of the area you take data from. This includes multiple pixels from TEMPO\n",
    "# (lon, lat, lon lat) for each area-- first set must be lower than the second!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f054db70-8f2c-4491-8a18-5bcd1cfe4a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected locations for coastal shrublands and grasslands\n",
    "bbox_list_csg= [(-120.55, 34.56, -120.54, 34.57),\n",
    "                (-120.46, 34.46, -120.45, 34.47),\n",
    "                (-120.32, 34.47, -120.31, 34.48),\n",
    "                (-119.34, 34.31, -119.33, 34.32),\n",
    "                (-119.23, 34.34, -119.22, 34.35),\n",
    "                (-119.20, 34.36, -119.19, 34.37),\n",
    "                (-117.38, 33.39, -117.37, 33.40),\n",
    "                (-117.34, 33.35, -117.33, 33.36),\n",
    "                (-117.47, 33.32, -117.46, 33.33),\n",
    "                (-117.36, 33.24, -117.35, 33.25)]\n",
    "# Call additional bbox lists different names!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f40b60-c4c0-4832-8833-b7f42958abb4",
   "metadata": {},
   "source": [
    "# ACCESSING TEMPO DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fffc73b-5b83-41cd-9d0d-b196045ffb26",
   "metadata": {},
   "source": [
    "The following procedure allows you to find the name of the TEMPO product you need. Select a date within your timeframe of interest and a single bounding box for simplicity. The workdir= locname portion creates a subfolder that the pyrsig package will use to store data. **You must delete these files or make a new locname each time you use a new bounding box.**\n",
    "\n",
    "In this example, I used a particular area in Southern California on December 18, 2023 to identify the product name for level 2 formaldehyde vertical column data. This allows data retrieval and analysis later.\n",
    " \n",
    " Filename format: TEMPO_{gas}_L2_VO3_{YYYY}{MM}{DD}T{HH}{NN}{SS}Z_S{XXX}G{YY}.nc\n",
    "\n",
    " {XXX} represents scan number, {YY} is granule number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5379939d-c2e0-4165-9146-29cc5e79736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOOKING FOR A PRODUCT NAME ---------------------------------------------------------------\n",
    "bdate_test= '2023-12-18' #bounding date-- YYYY-MM-DD format\n",
    "bbox_test = (-120.55, 34.56, -120.54, 34.57)\n",
    "\n",
    "api_test = pyrsig.RsigApi(bdate= bdate_test, bbox= bbox_test, workdir= locname, gridfit= True)\n",
    "api_key = 'anonymous' \n",
    "api_test.tempo_kw['api_key'] = api_key\n",
    "\n",
    "# After cell runs, scroll through the table to find the product you need\n",
    "# Use filters starting with \"tempo\" and modify search as needed.\n",
    "descdf = api.descriptions()\n",
    "descdf\n",
    "descdf.query('name.str.contains(\"tempo.l2.hcho\")') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f0eff7-50f6-458d-8a28-7e556d8332e8",
   "metadata": {},
   "source": [
    "# ACCESSING FORMALDEHYDE VERTICAL COLUMN DATA FOR 1 MONTH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c84c4b4-dd74-4ac4-a4f5-72aa00af1aae",
   "metadata": {},
   "source": [
    "TEMPO collects data every **daylight** hour. In my research, I chose to display this collection using histograms to visualize the data spread. The following script allows you to collect and manipulate data for an entire month for each of two regions. Empty lists for the autamation preparation must have unique names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dd9e45-55ef-4073-9bff-ccb2a223c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JULY 2024, HIGH ALTITUDE FORESTS AND WOODLANDS---------------------------------------\n",
    "\n",
    "# Preparing for an automated process\n",
    "api_key = 'anonymous'  # using public data, so using anonymous\n",
    "tempokey='tempo.l2.hcho.vertical_column' # defining a key for the TEMPO product of interest\n",
    "output_hafw=[] # reserving an empty list for the loop output\n",
    "\n",
    "# making a list of consecutive dates\n",
    "start_jul= '2024-07-01'\n",
    "end_jul= '2024-07-31'\n",
    "date_range_jul= pd.date_range(start= start_jul, end= end_jul)\n",
    "date_list_jul = date_range_jul.strftime('%Y-%m-%d').tolist() # this makes a list of usable strings\n",
    "jul_dates= pd.to_datetime(date_list_jul) # this converts strings to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6d00a5-bbb9-4aa0-8478-a6f3989708cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a loop: HCHO column for individual coordinates/bboxes\n",
    "#    It is essential that you do not put files from different bounding boxes in the same folder-- the data will not read\n",
    "#    properly. We use a number, i, in the locname (the folder it will make in the cloud) so that a new folder is made for\n",
    "#    each bounding box. By putting outputs in an empty list, the data will be together in the jupyter notebook when you\n",
    "#    are ready to use it. - Emily R. SARP West 2024\n",
    "i=-1\n",
    "for bbox in bbox_list:\n",
    "    i=i+1\n",
    "    locname = 'socal_new_'+str(i)\n",
    "    for day in jul_dates:\n",
    "        try:\n",
    "            api = pyrsig.RsigApi(bdate=day, bbox=bbox, workdir=locname, gridfit=(True))\n",
    "            api.tempo_kw['api_key'] = api_key\n",
    "            df = api.to_dataframe(tempokey, unit_keys=False, parse_dates=True, backend='xdr')\n",
    "            df['bbox'] = str(bbox) \n",
    "            \n",
    "            ## the next 3 lines are for indexing by bounding box\n",
    "            \n",
    "            df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce')\n",
    "            df['date'] = df['Timestamp'].dt.date\n",
    "            output_hafw.append(df) #adds output to empty list\n",
    "           #print(f'successfully processed date: {day} and bbox: {bbox}') # to print each successful run if needed\n",
    "        except Exception as e:\n",
    "            e = e\n",
    "            #print(f'an error occurred for date: {day} and bbox: {bbox}. Error: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1760d22-8410-4915-ba56-f6e81b7053f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JULY 2024 COASTAL SHRUBLANDS AND GRASSLANDS ----------------------------------------\n",
    "\n",
    "# Preparing for an automated process\n",
    "api_key = 'anonymous'  # using public, so using anonymous\n",
    "tempokey='tempo.l2.hcho.vertical_column' #defining a key for the TEMPO product of interest\n",
    "output_csg=[] # reserving an empty list for the loop output\n",
    "\n",
    "#making a loop: HCHO column for individual coordinates/bboxes\n",
    "# using same date list as high altitude forest and woodlands\n",
    "i=-1\n",
    "for bbox in bbox_list_csg:\n",
    "    i=i+1\n",
    "    locname = 'socal_jul_csg'+str(i)\n",
    "    for day in jul_dates:\n",
    "        \n",
    "        #print(bbox)\n",
    "        try:\n",
    "            api = pyrsig.RsigApi(bdate=day, bbox=bbox, workdir=locname, gridfit=(True))\n",
    "            api.tempo_kw['api_key'] = api_key\n",
    "            df = api.to_dataframe(tempokey, unit_keys=False, parse_dates=True, backend='xdr')\n",
    "            df['bbox'] = str(bbox)\n",
    "            df['Timestamp'] = pd.to_datetime(df['Timestamp'], errors='coerce')\n",
    "            df['date'] = df['Timestamp'].dt.date\n",
    "            output_csg.append(df) #adds output to empty list\n",
    "           #print(f'successfully processed date: {day} and bbox: {bbox}')\n",
    "        except Exception as e:\n",
    "            e = e\n",
    "            #print(f'an error occurred for date: {day} and bbox: {bbox}. Error: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8e1ccc-b836-470e-9f62-20630e98ce04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGING HIGH ALTITUDE FOREST & WOODLANDS AND COASTAL SHRUBLANDS & GRASSLANDS FOR JULY 2024\n",
    "df_highaltitude= pd.concat(output_hafw) # convert individual output lists to dataframes\n",
    "df_coastalshrub= pd.concat(output_csg)\n",
    "tempo_jul = [df_highaltitude, df_coastalshrub] # make a list of output dataframes\n",
    "df_tempo_jul = pd.concat(tempo_jul) # merge dataframes\n",
    "df_tempo_jul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92938a17-ea8f-48fd-b2a7-489437f04aae",
   "metadata": {},
   "source": [
    "# GRAPHING AND STATISTICS FOR 1 MONTH OF TEMPO DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1355d45-6a3a-4879-9f41-6a0f82da1aa5",
   "metadata": {},
   "source": [
    "The following cells demonstrate useful analyses for vertical column data. The examples below contain the code I used to analyze the formaldehyde vertical column data for the two regions in Southern California."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecea0dc-99a9-4dbf-8b62-c2242c052627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEDIANS FOR EACH PLANT CLASSIFICATION------------------------------------------------------\n",
    "median_hafw = np.median(df_highaltitude['vertical_column'])\n",
    "median_csg = np.median(df_coastalshrub['vertical_column'])\n",
    "print('median_hafw =', median_hafw)\n",
    "print('median_csg =', median_csg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a372cca4-e9c1-40dc-bf72-b91c220eeac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVERAGES FOR EACH PLANT CLASSIFICATION-----------------------------------------------------\n",
    "mean_hafw = df_highaltitude['vertical_column'].mean()\n",
    "mean_csg = df_coastalshrub['vertical_column'].mean()\n",
    "print('mean_hafw =', mean_hafw)\n",
    "print('mean_csg =', mean_csg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9c66f7-824a-4289-bea3-1f8a049ebb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STANDARD DEVIATION FOR EACH PLANT CLASSIFICTION-----------------------------------------------\n",
    "stdev_hafw = np.std(df_highaltitude['vertical_column'])\n",
    "stdev_csg = np.std(df_coastalshrub['vertical_column'])\n",
    "print('stdev_hafw =', stdev_hafw)\n",
    "print('stdev_csg=', stdev_csg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efa7019-e736-4950-aa71-974bcbc9f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING HISTOGRAMS FOR JULY 2024-----------------------------------------------------------\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)  # (rows, cols, panel number)\n",
    "plt.hist(df_highaltitude['vertical_column'], bins= 50, color='#3CA3FD', edgecolor='black')\n",
    "plt.title('HCHO Vertical Column - High Altitude Forests')\n",
    "plt.axvline(mean_hafw, color='black', linestyle='dashed', linewidth= 3.5, label=f'Mean: {mean_hafw:.2f}')\n",
    "plt.xlabel('HCHO Vertical Column')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim(0, 7.5e16)\n",
    "plt.ylim(0, 28)\n",
    "\n",
    "# Plot histogram for Coastal Shrublands\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(df_coastalshrub['vertical_column'], bins= 50, color='#FF00E7', edgecolor='black')\n",
    "plt.title('HCHO Vertical Column - Coastal Shrublands')\n",
    "plt.axvline(mean_csg, color='#0707CE', linestyle='dashed', linewidth= 3.5, label=f'Mean: {mean_hafw:.2f}')\n",
    "plt.xlabel('HCHO Vertical Column')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim(0, 7.5e16)\n",
    "plt.ylim(0, 28)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d254fdf-a5d4-4daf-88c2-c1721e4ceda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlaying thetwo plots above\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# High Altitude Forests and Woodlands\n",
    "plt.hist(df_highaltitude['vertical_column'], bins= 50, color='#3CA3FD', edgecolor='black')\n",
    "plt.axvline(mean_hafw, color='black', linestyle='dashed', linewidth= 3.5, label=f'Mean: {mean_hafw:.2f}')\n",
    "#plt.axvline(median_hafw, color = 'black', linestyle= ':' , linewidth = 3)\n",
    "\n",
    "plt.hist(df_coastalshrub['vertical_column'], bins= 50, color= '#FF00E7' , edgecolor='black')\n",
    "plt.title('HCHO Vertical Column')\n",
    "#plt.axvline(median_csg, color = 'blue', linestyle = ':', linewidth = 3)\n",
    "plt.axvline(mean_csg, color='#0707CE', linestyle= 'dashed', linewidth= 3.5, label=f'Mean: {mean_hafw:.2f}')\n",
    "plt.xlabel('HCHO Vertical Column')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.xlim(0, 7.5e16)\n",
    "plt.ylim(0, 28)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188d9008-6df9-45da-99fd-3beecdbc131e",
   "metadata": {},
   "source": [
    "# SIF DATA AQUISITION FOR MULTIPLE MONTHS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653a8bac-98fe-4226-93a6-5fc5c33d2e24",
   "metadata": {},
   "source": [
    "I used OCO-2 Solar-Induced Chlorophyll Fluorescence (SIF) data between May 2019 - December 2019 to observe trends in vegetation phenology which are consistent in the regions of interest. As of Aug. 2024, the OCO-2 data record only goes to 2020. \n",
    "\n",
    "The OCO-2 satellite has a 16 day return time, affording 2 measurements each month (I designate A and B below). Files are available for 0.5 degree coordinate intervals. \n",
    "\n",
    "The procedure below makes a dataframe containing longitude and latitude values for 10 bounding boxes at a time-- this can be modified as needed. I then use this to graph SIF trends for the same time interval that TEMPO data is available as of Aug. 2024. I had to go month-by-month, but there may be a way to automate this. My work can be used as a template if needed, but be very mindful of the names you assign to variables and datasets. \n",
    "\n",
    "**You will need to download individual files from Earth Data and upload them to the cloud for this procedure.**\n",
    "\n",
    "Source: https://daac.ornl.gov/cgi-bin/dsviewer.pl?ds_id=1863"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacdb3ad-ad42-45c9-bf6f-2377d3cbbe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making an empty list for merging all hafw sif dataframes\n",
    "df_sif_hafw=[]\n",
    "\n",
    "# Selected locations for high altitude forest and woodlands\n",
    "bbox_list_hafw= [(-118.40, 35.49, -118.35, 35.54),\n",
    "                 (-118.38, 35.45, -118.33, 35.50),\n",
    "                 (-118.33, 35.43, -118.28, 35.48),\n",
    "                 (-117.92, 34.06, -117.87, 34.11),\n",
    "                 (-116.75, 34.23, -116.70, 34.28),\n",
    "                 (-116.82, 34.01, -116.77, 34.06),\n",
    "                 (-117.79, 34.21, -117.74, 34.26),\n",
    "                 (-116.74, 33.84, -116.69, 33.89),\n",
    "                 (-117.56, 33.74, -117.51, 33.79),\n",
    "                 (-117.49, 33.66, -117.44, 33.71)]\n",
    "# bbox lists set the corners of the area you take data from\n",
    "# (lon, lat, lon lat) for each area-- first set must be lower than the second\n",
    "\n",
    "# Making a dataframe of coordinates to iterate through-- we need column names for the loop\n",
    "bbox_hafw = pd.DataFrame(bbox_list_hafw, columns=['lon_min', 'lat_min', 'lon_max', 'lat_max'])\n",
    "#bbox_hafw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf1b8bb-c684-4b82-b869-de3f2a0b47fe",
   "metadata": {},
   "source": [
    "DECEMBER 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed47be85-1a16-42b3-9dc3-0e3ad3ffd1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECEMBER A ----------------------------------------------------------\n",
    "\n",
    "# Making an empty list to store the first december measurement for each coordinate pair\n",
    "results_deca = []\n",
    "\n",
    "# Telling Python where to pull data from (upload Earth Data files to the cloud and copy the filepath)\n",
    "filepath_deca = '/home/jovyan/Emily_Rogers/Learning_SIF/sif_ann_201912a.nc'\n",
    "sifdeca = xr.open_dataset(filepath_deca)\n",
    "\n",
    "# Making a loop-- first telling it what each number is in the bbox list above\n",
    "for index, row in bbox_hafw.iterrows():\n",
    "    lon_min = row['lon_min']\n",
    "    lat_min = row['lat_min']\n",
    "    lon_max = row['lon_max']\n",
    "    lat_max = row['lat_max']\n",
    "\n",
    "    # Selecting data for each bounding box\n",
    "    sif_locdeca = sifdeca.sel(lat=slice(lat_min, lat_max), lon=slice(lon_min, lon_max))\n",
    "    sif_values_deca = sif_locdeca.sif_ann.values\n",
    "    #print(sif_values) # to check\n",
    "\n",
    "    # Flattening the array to make it easier to store in the DataFrame\n",
    "    flattened_values_deca = sif_values_deca.flatten() # this way, you won't have to extract numbers later\n",
    "\n",
    "    # Appending results to the list\n",
    "    results_deca.append({'lon_min': lon_min,\n",
    "                         'lat_min': lat_min,\n",
    "                         'lon_max': lon_max,\n",
    "                         'lat_max': lat_max,\n",
    "                         'sif_values': flattened_values_deca})\n",
    "\n",
    "df_deca_hafw = pd.DataFrame(results_deca) # converts results to dataframe\n",
    "df_deca_hafw['month'] = pd.Timestamp(year= 2019, month = 12, day=1).strftime('%m') # makes a month column\n",
    "#print(df_deca_hafw)\n",
    "df_sif_hafw.append(df_deca_hafw) # adds this dataset to what will be a combined list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de33fdce-602f-47d1-bb76-434fea2361bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECEMBER B-----------------------------------------------------------------\n",
    "results_decb = []\n",
    "\n",
    "filepath_decb='/home/jovyan/Emily_Rogers/Learning_SIF/sif_ann_201912b.nc' # opening the dataset\n",
    "sifdecb = xr.open_dataset(filepath_decb)\n",
    "\n",
    "for index, row in bbox_hafw.iterrows():\n",
    "    lon_min = row['lon_min']\n",
    "    lat_min = row['lat_min']\n",
    "    lon_max = row['lon_max']\n",
    "    lat_max = row['lat_max']\n",
    "\n",
    "    # Selecting data for each bounding box\n",
    "    sif_locdecb = sifdecb.sel(lat=slice(lat_min, lat_max), lon=slice(lon_min, lon_max))\n",
    "    sif_values_decb = sif_locdecb.sif_ann.values\n",
    "    #print(sif_values)\n",
    "\n",
    "    # Flattening the array to make it easier to store in the DataFrame\n",
    "    flattened_values_decb = sif_values_decb.flatten()\n",
    "\n",
    "    # Appending results to the list\n",
    "    results_decb.append({'lon_min': lon_min,\n",
    "                        'lat_min': lat_min,\n",
    "                        'lon_max': lon_max,\n",
    "                        'lat_max': lat_max,\n",
    "                        'sif_values': flattened_values_decb})\n",
    "\n",
    "df_decb_hafw = pd.DataFrame(results_decb) # converts results to dataframe\n",
    "df_decb_hafw['month'] = pd.Timestamp(year= 2019, month = 12, day=1).strftime('%m')\n",
    "#print(df_decb_hafw)\n",
    "df_sif_hafw.append(df_decb_hafw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356faed4-280b-4bf6-b754-a36f36e092bf",
   "metadata": {},
   "source": [
    "NOVEMBER 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402a2e9c-6c59-4d5f-bc93-ba017245a732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOVEMBER A -------------------------------------------------------\n",
    "results_nova = []\n",
    "\n",
    "filepath_nova='/home/jovyan/Emily_Rogers/Learning_SIF/sif_ann_201911a.nc'\n",
    "sifnova = xr.open_dataset(filepath_nova)\n",
    "\n",
    "for index, row in bbox_hafw.iterrows():\n",
    "    lon_min = row['lon_min']\n",
    "    lat_min = row['lat_min']\n",
    "    lon_max = row['lon_max']\n",
    "    lat_max = row['lat_max']\n",
    "\n",
    "    # Selecting data for each bounding box\n",
    "    sif_locnova = sifnova.sel(lat=slice(lat_min, lat_max), lon=slice(lon_min, lon_max))\n",
    "    sif_values_nova = sif_locnova.sif_ann.values\n",
    "    #print(sif_values)\n",
    "\n",
    "    # Flattening the array to make it easier to store in the DataFrame\n",
    "    flattened_values_nova = sif_values_nova.flatten()\n",
    "\n",
    "    # Appending results to the list\n",
    "    results_nova.append({'lon_min': lon_min,\n",
    "                          'lat_min': lat_min,\n",
    "                         'lon_max': lon_max,\n",
    "                         'lat_max': lat_max,\n",
    "                         'sif_values': flattened_values_nova})\n",
    "\n",
    "df_nova_hafw = pd.DataFrame(results_nova) # converts results to dataframe\n",
    "df_nova_hafw['month'] = pd.Timestamp(year= 2019, month = 11, day=1).strftime('%m')\n",
    "#print(df_nova_hafw)\n",
    "df_sif_hafw.append(df_nova_hafw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa67493a-d489-4c70-a0b3-e4aad221100d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOVEMBER B -------------------------------------------------------\n",
    "results_novb = []\n",
    "\n",
    "filepath_novb='/home/jovyan/Emily_Rogers/Learning_SIF/sif_ann_201911b.nc'\n",
    "sifnovb = xr.open_dataset(filepath_novb)\n",
    "\n",
    "for index, row in bbox_hafw.iterrows():\n",
    "    lon_min = row['lon_min']\n",
    "    lat_min = row['lat_min']\n",
    "    lon_max = row['lon_max']\n",
    "    lat_max = row['lat_max']\n",
    "\n",
    "    # Selecting data for each bounding box\n",
    "    sif_locnovb = sifnovb.sel(lat=slice(lat_min, lat_max), lon=slice(lon_min, lon_max))\n",
    "    sif_values_novb = sif_locnovb.sif_ann.values\n",
    "    #print(sif_values)\n",
    "\n",
    "    # Flattening the array to make it easier to store in the DataFrame\n",
    "    flattened_values_novb = sif_values_novb.flatten()\n",
    "\n",
    "    # Appending results to the list\n",
    "    results_novb.append({'lon_min': lon_min,\n",
    "                         'lat_min': lat_min,\n",
    "                         'lon_max': lon_max,\n",
    "                         'lat_max': lat_max,\n",
    "                         'sif_values': flattened_values_novb})\n",
    "\n",
    "df_novb_hafw = pd.DataFrame(results_novb) # converts results to dataframe\n",
    "df_novb_hafw['month'] = pd.Timestamp(year= 2019, month = 11, day=1).strftime('%m')\n",
    "#print(df_novb_hafw)\n",
    "df_sif_hafw.append(df_novb_hafw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a09186-9f0a-4479-b3ba-55047c8b0d02",
   "metadata": {},
   "source": [
    "OCTOBER 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7eac89-3a51-41ea-a603-78bbc2d91a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCTOBER A -------------------------------------------------------\n",
    "results_octa = []\n",
    "\n",
    "filepath_octa='/home/jovyan/Emily_Rogers/Learning_SIF/sif_ann_201910a.nc'\n",
    "sifocta = xr.open_dataset(filepath_octa)\n",
    "\n",
    "for index, row in bbox_hafw.iterrows():\n",
    "    lon_min = row['lon_min']\n",
    "    lat_min = row['lat_min']\n",
    "    lon_max = row['lon_max']\n",
    "    lat_max = row['lat_max']\n",
    "\n",
    "    # Selecting data for each bounding box\n",
    "    sif_lococta = sifocta.sel(lat=slice(lat_min, lat_max), lon=slice(lon_min, lon_max))\n",
    "    sif_values_octa = sif_lococta.sif_ann.values\n",
    "    #print(sif_values)\n",
    "\n",
    "    # Flattening the array to make it easier to store in the DataFrame\n",
    "    flattened_values_octa = sif_values_octa.flatten()\n",
    "\n",
    "    # Appending results to the list\n",
    "    results_octa.append({'lon_min': lon_min,\n",
    "                         'lat_min': lat_min,\n",
    "                         'lon_max': lon_max,\n",
    "                         'lat_max': lat_max,\n",
    "                         'sif_values': flattened_values_octa})\n",
    "\n",
    "df_octa_hafw = pd.DataFrame(results_octa) # converts results to dataframe\n",
    "df_octa_hafw['month'] = pd.Timestamp(year= 2019, month = 10, day=1).strftime('%m')\n",
    "#print(df_octa_hafw)\n",
    "df_sif_hafw.append(df_octa_hafw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa60ab3-4fcb-4592-b2af-922857a4833c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCTOBER B -------------------------------------------------------\n",
    "results_octb = []\n",
    "\n",
    "filepath_octb='/home/jovyan/Emily_Rogers/Learning_SIF/sif_ann_201910b.nc'\n",
    "sifoctb = xr.open_dataset(filepath_octb)\n",
    "\n",
    "for index, row in bbox_hafw.iterrows():\n",
    "    lon_min = row['lon_min']\n",
    "    lat_min = row['lat_min']\n",
    "    lon_max = row['lon_max']\n",
    "    lat_max = row['lat_max']\n",
    "\n",
    "    # Selecting data for each bounding box\n",
    "    sif_lococtb = sifoctb.sel(lat=slice(lat_min, lat_max), lon=slice(lon_min, lon_max))\n",
    "    sif_values_octb = sif_lococtb.sif_ann.values\n",
    "    #print(sif_values)\n",
    "\n",
    "    # Flattening the array to make it easier to store in the DataFrame\n",
    "    flattened_values_octb = sif_values_octb.flatten()\n",
    "\n",
    "    # Appending results to the list\n",
    "    results_octb.append({'lon_min': lon_min,\n",
    "                         'lat_min': lat_min,\n",
    "                         'lon_max': lon_max,\n",
    "                         'lat_max': lat_max,\n",
    "                         'sif_values': flattened_values_octb})\n",
    "\n",
    "df_octb_hafw = pd.DataFrame(results_octb) # converts results to dataframe\n",
    "df_octb_hafw['month'] = pd.Timestamp(year= 2019, month = 10, day=1).strftime('%m')\n",
    "#print(df_octb_hafw)\n",
    "df_sif_hafw.append(df_octb_hafw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a994df28-53a5-4646-ac51-be869e965b15",
   "metadata": {},
   "source": [
    "SEPTEMBER 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e63e061-2857-4978-829b-5c325dcb13f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEPTEMBER A -------------------------------------------------------------\n",
    "results_sepa = []\n",
    "\n",
    "filepath_sepa='/home/jovyan/Emily_Rogers/Learning_SIF/sif_ann_201909a.nc'\n",
    "sifsepa = xr.open_dataset(filepath_sepa)\n",
    "\n",
    "for index, row in bbox_hafw.iterrows():\n",
    "    lon_min = row['lon_min']\n",
    "    lat_min = row['lat_min']\n",
    "    lon_max = row['lon_max']\n",
    "    lat_max = row['lat_max']\n",
    "\n",
    "    # Selecting data for each bounding box\n",
    "    sif_locsepa = sifsepa.sel(lat=slice(lat_min, lat_max), lon=slice(lon_min, lon_max))\n",
    "    sif_values_sepa = sif_locsepa.sif_ann.values\n",
    "    #print(sif_values)\n",
    "\n",
    "    # Flattening the array to make it easier to store in the DataFrame\n",
    "    flattened_values_sepa = sif_values_sepa.flatten()\n",
    "\n",
    "    # Appending results to the list\n",
    "    results_sepa.append({'lon_min': lon_min,\n",
    "                         'lat_min': lat_min,\n",
    "                         'lon_max': lon_max,\n",
    "                         'lat_max': lat_max,\n",
    "                         'sif_values': flattened_values_sepa})\n",
    "\n",
    "df_sepa_hafw = pd.DataFrame(results_sepa) # converts results to dataframe\n",
    "df_sepa_hafw['month'] = pd.Timestamp(year= 2019, month = 9, day=1).strftime('%m') \n",
    "#print(df_sepa_hafw)\n",
    "df_sif_hafw.append(df_sepa_hafw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c735570a-49b8-4acc-a535-c88aaa124a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEPTEMBER B -------------------------------------------------------------\n",
    "results_sepb = []\n",
    "\n",
    "filepath_sepb='/home/jovyan/Emily_Rogers/Learning_SIF/sif_ann_201909b.nc'\n",
    "sifsepb = xr.open_dataset(filepath_sepb)\n",
    "\n",
    "for index, row in bbox_hafw.iterrows():\n",
    "    lon_min = row['lon_min']\n",
    "    lat_min = row['lat_min']\n",
    "    lon_max = row['lon_max']\n",
    "    lat_max = row['lat_max']\n",
    "\n",
    "    # Selecting data for each bounding box\n",
    "    sif_locsepb = sifsepb.sel(lat=slice(lat_min, lat_max), lon=slice(lon_min, lon_max))\n",
    "    sif_values_sepb = sif_locsepb.sif_ann.values\n",
    "    #print(sif_values)\n",
    "\n",
    "    # Flattening the array to make it easier to store in the DataFrame\n",
    "    flattened_values_sepb = sif_values_sepb.flatten()\n",
    "\n",
    "    # Appending results to the list\n",
    "    results_sepb.append({'lon_min': lon_min,\n",
    "                         'lat_min': lat_min,\n",
    "                         'lon_max': lon_max,\n",
    "                         'lat_max': lat_max,\n",
    "                         'sif_values': flattened_values_sepb})\n",
    "\n",
    "df_sepb_hafw = pd.DataFrame(results_sepb) # converts results to dataframe\n",
    "df_sepb_hafw['month'] = pd.Timestamp(year= 2019, month = 9, day=1).strftime('%m')\n",
    "#print(df_sepb_hafw)\n",
    "df_sif_hafw.append(df_sepb_hafw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18e6fbb-2df7-4b86-89b5-e647d5b60699",
   "metadata": {},
   "source": [
    "AUGUST 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59d109d-40db-4488-bc76-585b2b317e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUGUST A --------------------------------------------------------------------------------\n",
    "results_auga = []\n",
    "\n",
    "filepath_auga='/home/jovyan/Emily_Rogers/Learning_SIF/sif_ann_201908a.nc'\n",
    "sifauga = xr.open_dataset(filepath_auga)\n",
    "\n",
    "for index, row in bbox_hafw.iterrows():\n",
    "    lon_min = row['lon_min']\n",
    "    lat_min = row['lat_min']\n",
    "    lon_max = row['lon_max']\n",
    "    lat_max = row['lat_max']\n",
    "\n",
    "    # Selecting data for each bounding box\n",
    "    sif_locauga = sifauga.sel(lat=slice(lat_min, lat_max), lon=slice(lon_min, lon_max))\n",
    "    sif_values_auga = sif_locauga.sif_ann.values\n",
    "    #print(sif_values)\n",
    "\n",
    "    # Flattening the array to make it easier to store in the DataFrame\n",
    "    flattened_values_auga = sif_values_auga.flatten()\n",
    "\n",
    "    # Appending results to the list\n",
    "    results_auga.append({'lon_min': lon_min,\n",
    "                         'lat_min': lat_min,\n",
    "                         'lon_max': lon_max,\n",
    "                         'lat_max': lat_max,\n",
    "                         'sif_values': flattened_values_auga})\n",
    "\n",
    "df_auga_hafw = pd.DataFrame(results_auga) # converts results to dataframe\n",
    "df_auga_hafw['month'] = pd.Timestamp(year= 2019, month = 8, day=1).strftime('%m')\n",
    "#print(df_auga_hafw)\n",
    "df_sif_hafw.append(df_auga_hafw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2b5d4c-27e0-42f8-a5d1-6e383de807b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUGUST B ----------------------------------------------------------------------------------\n",
    "results_augb = []\n",
    "\n",
    "filepath_augb='/home/jovyan/Emily_Rogers/Learning_SIF/sif_ann_201908b.nc'\n",
    "sifaugb = xr.open_dataset(filepath_augb)\n",
    "\n",
    "for index, row in bbox_hafw.iterrows():\n",
    "    lon_min = row['lon_min']\n",
    "    lat_min = row['lat_min']\n",
    "    lon_max = row['lon_max']\n",
    "    lat_max = row['lat_max']\n",
    "\n",
    "    # Selecting data for each bounding box\n",
    "    sif_locaugb = sifaugb.sel(lat=slice(lat_min, lat_max), lon=slice(lon_min, lon_max))\n",
    "    sif_values_augb = sif_locaugb.sif_ann.values\n",
    "    #print(sif_values)\n",
    "\n",
    "    # Flattening the array to make it easier to store in the DataFrame\n",
    "    flattened_values_augb = sif_values_augb.flatten()\n",
    "\n",
    "    # Appending results to the list\n",
    "    results_augb.append({'lon_min': lon_min,\n",
    "                         'lat_min': lat_min,\n",
    "                         'lon_max': lon_max,\n",
    "                         'lat_max': lat_max,\n",
    "                         'sif_values': flattened_values_augb})\n",
    "\n",
    "df_augb_hafw = pd.DataFrame(results_augb) # converts results to dataframe\n",
    "df_augb_hafw['month'] = pd.Timestamp(year= 2019, month = 8, day=1).strftime('%m')\n",
    "#print(df_auga_hafw)\n",
    "df_sif_hafw.append(df_augb_hafw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babaa988-bfbb-40a1-81ee-7f433998d9bc",
   "metadata": {},
   "source": [
    "JULY 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84938b3-1411-4cd0-af54-9c089ca69ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JULY A ---------------------------------------------------------------------------------------\n",
    "results_jula = []\n",
    "\n",
    "filepath_jula='/home/jovyan/Emily_Rogers/Learning_SIF/sif_ann_201907a.nc'\n",
    "sifjula = xr.open_dataset(filepath_jula)\n",
    "\n",
    "for index, row in bbox_hafw.iterrows():\n",
    "    lon_min = row['lon_min']\n",
    "    lat_min = row['lat_min']\n",
    "    lon_max = row['lon_max']\n",
    "    lat_max = row['lat_max']\n",
    "\n",
    "    # Selecting data for each bounding box\n",
    "    sif_locjula = sifjula.sel(lat=slice(lat_min, lat_max), lon=slice(lon_min, lon_max))\n",
    "    sif_values_jula = sif_locjula.sif_ann.values\n",
    "    #print(sif_values)\n",
    "\n",
    "    # Flattening the array to make it easier to store in the DataFrame\n",
    "    flattened_values_jula = sif_values_jula.flatten()\n",
    "\n",
    "    # Appending results to the list\n",
    "    results_jula.append({'lon_min': lon_min,\n",
    "                         'lat_min': lat_min,\n",
    "                         'lon_max': lon_max,\n",
    "                         'lat_max': lat_max,\n",
    "                         'sif_values': flattened_values_jula})\n",
    "\n",
    "df_jula_hafw = pd.DataFrame(results_jula) # converts results to dataframe\n",
    "df_jula_hafw['month'] = pd.Timestamp(year= 2019, month = 7, day=1).strftime('%m')\n",
    "#print(df_jula_hafw)\n",
    "df_sif_hafw.append(df_jula_hafw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143506e1-9578-4df1-81ef-cce100bd5e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JULY B --------------------------------------------------------------------------------------\n",
    "results_julb = []\n",
    "\n",
    "filepath_julb='/home/jovyan/Emily_Rogers/Learning_SIF/sif_ann_201907b.nc'\n",
    "sifjulb = xr.open_dataset(filepath_julb)\n",
    "\n",
    "for index, row in bbox_hafw.iterrows():\n",
    "    lon_min = row['lon_min']\n",
    "    lat_min = row['lat_min']\n",
    "    lon_max = row['lon_max']\n",
    "    lat_max = row['lat_max']\n",
    "\n",
    "    # Selecting data for each bounding box\n",
    "    sif_locjulb = sifjulb.sel(lat=slice(lat_min, lat_max), lon=slice(lon_min, lon_max))\n",
    "    sif_values_julb = sif_locjulb.sif_ann.values\n",
    "    #print(sif_values)\n",
    "\n",
    "    # Flattening the array to make it easier to store in the DataFrame\n",
    "    flattened_values_julb = sif_values_julb.flatten()\n",
    "\n",
    "    # Appending results to the list\n",
    "    results_julb.append({'lon_min': lon_min,\n",
    "                         'lat_min': lat_min,\n",
    "                         'lon_max': lon_max,\n",
    "                         'lat_max': lat_max,\n",
    "                         'sif_values': flattened_values_julb})\n",
    "\n",
    "df_julb_hafw = pd.DataFrame(results_julb) # converts results to dataframe\n",
    "df_julb_hafw['month'] = pd.Timestamp(year= 2019, month = 7, day=1).strftime('%m')\n",
    "print(df_julb_hafw)\n",
    "df_sif_hafw.append(df_julb_hafw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fff3e1e-48e7-4287-8679-7a013c0f4cb8",
   "metadata": {},
   "source": [
    "JUNE 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7031a3-c907-4f57-b9c1-e8c50b4f390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUNE A ---------------------------------------------------------------------------------------\n",
    "results_juna = []\n",
    "\n",
    "filepath_juna='/home/jovyan/Emily_Rogers/Learning_SIF/sif_ann_201906a.nc'\n",
    "sifjuna = xr.open_dataset(filepath_juna)\n",
    "\n",
    "for index, row in bbox_hafw.iterrows():\n",
    "    lon_min = row['lon_min']\n",
    "    lat_min = row['lat_min']\n",
    "    lon_max = row['lon_max']\n",
    "    lat_max = row['lat_max']\n",
    "\n",
    "    # Selecting data for each bounding box\n",
    "    sif_locjuna = sifjuna.sel(lat=slice(lat_min, lat_max), lon=slice(lon_min, lon_max))\n",
    "    sif_values_juna = sif_locjuna.sif_ann.values\n",
    "    #print(sif_values)\n",
    "\n",
    "    # Flattening the array to make it easier to store in the DataFrame\n",
    "    flattened_values_juna = sif_values_juna.flatten()\n",
    "\n",
    "    # Appending results to the list\n",
    "    results_juna.append({'lon_min': lon_min,\n",
    "                         'lat_min': lat_min,\n",
    "                         'lon_max': lon_max,\n",
    "                         'lat_max': lat_max,\n",
    "                         'sif_values': flattened_values_juna})\n",
    "\n",
    "df_juna_hafw = pd.DataFrame(results_juna) # converts results to dataframe\n",
    "df_juna_hafw['month'] = pd.Timestamp(year= 2019, month = 6, day=1).strftime('%m')\n",
    "#print(df_juna_hafw)\n",
    "df_sif_hafw.append(df_juna_hafw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50f731d-ba78-46b1-9d88-dfe196c4e252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUNE B ---------------------------------------------------------------------------------------\n",
    "results_junb = []\n",
    "\n",
    "filepath_junb='/home/jovyan/Emily_Rogers/Learning_SIF/sif_ann_201906b.nc'\n",
    "sifjunb = xr.open_dataset(filepath_junb)\n",
    "\n",
    "for index, row in bbox_hafw.iterrows():\n",
    "    lon_min = row['lon_min']\n",
    "    lat_min = row['lat_min']\n",
    "    lon_max = row['lon_max']\n",
    "    lat_max = row['lat_max']\n",
    "\n",
    "    # Selecting data for each bounding box\n",
    "    sif_locjunb = sifjunb.sel(lat=slice(lat_min, lat_max), lon=slice(lon_min, lon_max))\n",
    "    sif_values_junb = sif_locjunb.sif_ann.values\n",
    "    #print(sif_values)\n",
    "\n",
    "    # Flattening the array to make it easier to store in the DataFrame\n",
    "    flattened_values_junb = sif_values_junb.flatten()\n",
    "\n",
    "    # Appending results to the list\n",
    "    results_junb.append({'lon_min': lon_min,\n",
    "                         'lat_min': lat_min,\n",
    "                         'lon_max': lon_max,\n",
    "                         'lat_max': lat_max,\n",
    "                         'sif_values': flattened_values_junb})\n",
    "\n",
    "df_junb_hafw = pd.DataFrame(results_junb) # converts results to dataframe\n",
    "df_junb_hafw['month'] = pd.Timestamp(year= 2019, month = 6, day=1).strftime('%m')\n",
    "#print(df_junb_hafw)\n",
    "df_sif_hafw.append(df_junb_hafw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13dc340-39eb-4c69-977d-9f95e2bc42e9",
   "metadata": {},
   "source": [
    "MAY 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db96931-0e49-42b8-ba59-d0d554891e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAY B (no TEMPO data for May A for comparison)-----------------------------------------------\n",
    "results_mayb = []\n",
    "\n",
    "filepath_mayb='/home/jovyan/Emily_Rogers/Learning_SIF/sif_ann_201905b.nc'\n",
    "sifmayb = xr.open_dataset(filepath_mayb)\n",
    "\n",
    "for index, row in bbox_hafw.iterrows():\n",
    "    lon_min = row['lon_min']\n",
    "    lat_min = row['lat_min']\n",
    "    lon_max = row['lon_max']\n",
    "    lat_max = row['lat_max']\n",
    "\n",
    "    # Selecting data for each bounding box\n",
    "    sif_locmayb = sifmayb.sel(lat=slice(lat_min, lat_max), lon=slice(lon_min, lon_max))\n",
    "    sif_values_mayb = sif_locmayb.sif_ann.values\n",
    "    #print(sif_values)\n",
    "\n",
    "    # Flattening the array to make it easier to store in the DataFrame\n",
    "    flattened_values_mayb = sif_values_mayb.flatten()\n",
    "\n",
    "    # Appending results to the list\n",
    "    results_mayb.append({'lon_min': lon_min,\n",
    "                         'lat_min': lat_min,\n",
    "                         'lon_max': lon_max,\n",
    "                         'lat_max': lat_max,\n",
    "                         'sif_values': flattened_values_mayb})\n",
    "\n",
    "df_mayb_hafw = pd.DataFrame(results_mayb) # converts results to dataframe\n",
    "df_mayb_hafw['month'] = pd.Timestamp(year= 2019, month = 5, day=1).strftime('%m')\n",
    "print(df_mayb_hafw)\n",
    "df_sif_hafw.append(df_mayb_hafw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06afe1b-6401-4f10-b536-43110525ffe8",
   "metadata": {},
   "source": [
    "# GRAPHING MONTHLY SIF DATA FOR HIGH ALTITUDE FORESTS AND WOODLANDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6916e20-6b7b-4a54-b2ab-2f565b05b5e3",
   "metadata": {},
   "source": [
    "I used the following code to graph the relationship between formaldehyde concentration and the SIF over each region of interest for the available time interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e252364-0545-43ab-a736-729d383e58d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGING DATAFRAMES FOR HIGH ALTITUDE FORESTS AND WOODLANDS-----------------------------------\n",
    "sif_hafw= pd.concat(df_sif_hafw)\n",
    "sif_hafw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5e23cf-33be-468a-8bb4-bb680bc9d438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKING A DATAFRAME FOR MONTHLY AVERAGE--------------------------------------------------\n",
    "avg_sif = sif_hafw.groupby('month', as_index=False)['sif_values'].mean()\n",
    "avg_sif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918502d8-9b82-4a13-b270-f99194da117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you get values in brackets and gets errors, use the following and then try the cell above again.\n",
    "\n",
    "#sif_hafw['sif_values_str'] = sif_hafw['sif_values'].astype(str) # extracts values from brackets\n",
    "#sif_hafw['sif_values'] = sif_hafw['sif_values'].str.extract(r'(\\d+)').astype(float) # converts sif values as a number\n",
    "#sif_hafw # to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd23b79-9b1a-4ed2-aecd-faa8eba079af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING HIGH ALTITUDE FORESTS AND WOODLANDS ----------------------------------------------\n",
    "plt.plot(avg_sif['month'], avg_sif['sif_values'])\n",
    "plt.title('Average SIF for High Altitude Forest and Woodlands')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Average SIF')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
